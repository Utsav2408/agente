extract_student_id_task:
  description: |
    **INPUTS** 
      User Input: '{user_query}'

      Metadata:
      Student_Id: '{student_id}'

    Your task is to find the student id either from user input.
    The format of student ID is DDDD (4 digits).

    - If you were not able to find the student ID in User Input, then check Metadata.
    - If Student_Id in Metadata is also empty, then return empty string.

  expected_output: |
    A JSON object with the following fields:
    {
      "student_id": The student ID found or empty
    }
  agent: evaluation_student_id_fetcher

extract_suggested_evaluation_feedback_task:
  description: |
    **INPUTS** 
    Student ID: Take student_id from previous task
    Class: {class}
    Exam: {exam}
    Subject: {subject}

    Your task is to call 'get_evaluation_feedback' tool using payload:
    {
      "student_id": The given student_id as input,
      "grade": The given class as input,
      "exam_type": The given exam as input,
      "course_name": The given subject as input
    }
    Then return the raw response recieved from tool call.
  expected_output: |
    A JSON object with the following fields:
    {
      "student_id": The given student_id as input
      "suggested_evaluation_feedback_list": This should contain the response from tool call
    }
  # expected_output: |
  #   A JSON object with the following fields:
  #   {
  #     "suggested_evaluation_feedback": This should contain the response from tool call
  #   }
  agent: evaluation_feedback_fetcher


# beautify_suggested_evaluation_feedback_task:
#   description: |
#     **INPUTS**  
#     Student ID: Take student_id from previous task
#     Suggested Evaluation Feedback Tool response: Take suggested_evaluation_feedback from previous task

#     Student ID includes the ID of the student for whom evaluation is being done,
#     Suggested Evaluation Feedback Tool Response holds a list of JSONs, where each JSON holds the following information -
#     - question: The question came in exam,
#     - answer_key: The answer given by instructor for the given question,
#     - student_answer: The answer given by student for the given question,
#     - total_mark: The total marks alloted to the question in the exam,
#     - individual_mark: The marks alloted to the student based on their answer,
#     - similarity_score: This score indicates how much percentage of content of student's answer is similar to the answer key,
#     - feedback: The feedback given to the student based on their answer

#     Your task is to draft the section of "Suggested Evaluation Feedback".
#     - First have a title: "Suggested Evaluation Feedback".
#     - Then, each JSON from the list of Suggested Evaluation Feedback Tool Response, should be presented as a subsection with appropriate spacing and alignment.
#       - Each subsection should contain the Question Number as a Title then the question, answer_key, student_answer, total_marks, individual_mark, similarity_score and feedback as the contents

#     Make sure your draft is clear and well formatted. 

#   expected_output: |
#     A JSON object with the following three fields:
#     {
#       "student_id": The given student_id as input
#       "suggested_evaluation_feedback_list": The JSON having suggested_evaluation_feedback from previous task
#       "suggested_evaluation_feedback_section": The draft of the section "Suggested Evaluation Feedback" generated by you
#     }
#   agent: evaluation_feedback_beautifier
